# What is GPU
- GPU设计目标是最大化吞吐量，比单任务执行慢，更关心并行度。
- CPU更关心延迟和并发。 


## Demo “AX+Y”
CPU：
1. 并行：同时处理多个任务
2. 并发：能够处理多个任务的功能，但不一定是同时

硬件架构栈线程区别：
1. GPU时延比CPU高出好几倍
2. GPU线程数是CPU的二三十倍

GPU设计特点：线程非常多，不去关注数据搬运的延迟和执行指令的延迟
<br/>
CPU设计特点：优化一个线程中执行的效率和速率。

## GPU CACHE
 
## GPU THREAD
每个SM里有大量的wrap线程，每个wrap可以同时去并行执行多个线程
每个SM里有线程的调度器，寄存器。

## 卷积的实现过程
Img2col 对Input进行重排，卷积核进行展开，卷积的计算转换为两个矩阵相乘的求解

## AI计算模式与线程的关系
用网格Grid进行覆盖，Grid中块Blocks，Block中线程Threads通过本地数据共享来计算
- 网格Grid表实所有要执行的任务
- 网格Grid中包含了很多相同线程Threads数量的块Blocks
- 块Block中的线程数独立执行，可以通过本地数据共享，同步交换数据

计算和带宽的平衡点

### GPU概念之间的关系
- GPC 图形处理簇
- TPC 纹理处理簇
- SM  流多处理器
- HBM 高带宽存储器

## SM(多流式处理器)
核心组件包括CUDA核心，共享内存，寄存器等。
SM包含许多为线程执行数学运算的core，是NVIDA核心

SM里面可以并发地执行数百个线程。

线程是软件的概念，对于硬件是指令分发单元

### Wrap线程束
- 逻辑上，所有Thread是并行；但是从硬件的角度来说，并不是所有的Thread能够在同一时刻执行，这里就要Wrap。

- Wrap是SM基本执行单元，一个Wrap包含32个并行Thread，这32个Thread执行于SIMT模式。所有Thread以锁步的方式执行同一条指令，
但每个Thread回使用各自的Data执行指令分支。如果在Wrap中没有32个Thread需要工作，那么Wrap虽然还是作为一个整体运行，
但这边部分Thread是处于非激活状态。
